{
    "contents" : "Project to Practical Machine Learning\n========================================================\nPaul Nommensen, 20-06-2014\n\nIntroduction\n------------\n\nThis work was done in the frame of the Coursera course Practical Machine learning.\n\nData was obtained from [http://groupware.les.inf.puc-rio.br/har](http://groupware.les.inf.puc-rio.br/har).  6 participants were asked to perform barbell lifts correctly and incorrectly in 5 different ways. Data was collected from accelerometers on the belt, forearm, arm, and dumbell. Goal of the project is to predict the way in which the barbell was lifted.\n\n```{r, message=FALSE, warning=FALSE}\nlibrary(caret)\n```\n\nLoading the data\n----------------\n```{r}\ndata <-  read.csv(\"data/pml-training.csv\", na.strings = c(\"NA\", \"\", \"#DIV/0!\"))\n```\nNote that the error message #DIV>0! in the data file are treated as a NA.\n\nCleansing the data\n------------------\nMany columns contain mainly NA's. These columns are removed from the data set.\n```{r }\ncountNA <- function(x) (sum(is.na(x)))\nnoNA <- (sapply(data,countNA)==0)\ndata <- data[,noNA]\n\ndim(data)\n```\n\nCovariate selection\n-------------------\nSome of the parameters contain information that seems to be irrelvant. The paramter x presents the order in which the observation were done. Also the actual moment in time the exercise was performed can not be used as a predictor because when an obervation is done at a later time it is out of range. So the parameters X, raw_timestamp_part_1, raw_timestamp_part_2 and cvtd_timestamp are removed from the data set. \n\nThe parameters new_window and num_window also seems to indicate the orderin which the observation were done. It is anticipated that these do not contain real information on the way a excersise was done. So both are removed from the data set.\n\nNote that the same persons are present in the test-dataset. So the paramter name can still be used in the predictions.\n \n```{r}\ndata <- data[,c(-1,-3, -4, -5, -6, -7)]\n```\n\nSlicing the data\n----------------\nThe data set is splitted in a training, test and validation set. The sets contain 60%, 20% and 20% of the data.\n```{r}\nset.seed(43563)\nintrain <- createDataPartition(y = data$classe, p=0.6, list=FALSE)\ntraining <- data[intrain,]\ntesting <-  data[-intrain,]\n\ninvalidate <- createDataPartition(y = testing$classe, p=0.5, list = FALSE)\nvalidate   <- testing[invalidate,]\ntesting    <- testing[-invalidate,]\n\n```\n\nPrepare a prediction model\n--------------------------\n### Predicting with a classification tree\n```{r, message=FALSE , warning=FALSE}\nmodTree <- train(classe ~ . , method = \"rpart\", data=training)\nprint(modTree)\n```\n\n```{r, message=FALSE , warning=FALSE}\nprediction <- predict(modTree, newdata=testing) \nc<-confusionMatrix(prediction, testing$classe)\naccTree <- c$overall[1]\nprint(c)\n```\n\n### Predicting with Linear discriminant analysis\nAnother prediction algorithm is lda. In order to overcome the correlations among the predictors a PCA is performed on them and the PCA-scores are used in the modeling\n```{r, message=FALSE , warning=FALSE}\nmodLDA <- train(classe ~ . , method = \"lda\", preProcess=\"pca\", data=training)\n```\n\n```{r, message=FALSE , warning=FALSE}\nprediction <- predict(modLDA, newdata=testing) \nc<-confusionMatrix(prediction, testing$classe)\naccLDA <- c$overall[1]\nprint(c)\n```\n### Predicting with a random forrest\n```{r, message=FALSE , warning=FALSE}\nmodRF <- train(classe ~ . , method = \"rf\", data=training, prox=TRUE)\nprint(modRF)\n```\n\n```{r, message=FALSE , warning=FALSE}\nprediction <- predict(modRF, newdata=testing) \nc<-confusionMatrix(prediction, testing$classe)\naccRF <- c$overall[1]\nprint(c)\n```\n\nSelecting the optimal model\n---------------------------\nSeveral algorithms were tested. \n* CART with a accuracy from cross validation of `r accTree`.\n* LDA with a accuracy from cross validation of `r accLDA`.\n* Random forrest with a accuracy from cross validation of `r accRF`.\n\nBased on the accuracy in predicting the test set,  the random forest model is selected as the optimal model. \n\n\nThe out of sample Error\n----------------------\nThe randomforest model is used to predicted a validation set.\n\n```{r}\nprediction <- predict(modRF, newdata=validate) \nc<-confusionMatrix(prediction, testing$classe)\naccVal <- c$overall[1]\nprint(c)\n```\n\n__The accuracy on the validation set is `r accVal`. This indicates the model works rather well.__ This number is also close the result of the cross validation.\n",
    "created" : 1403247925447.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3491379609",
    "id" : "B0F00068",
    "lastKnownWriteTime" : 1403267987,
    "path" : "~/Coursera/Practical-Machine-Learning/project.Rmd",
    "project_path" : "project.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}